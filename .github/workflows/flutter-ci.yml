name: Flutter CI/CD with Security Scanning

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:  # Allow manual triggers

permissions:
  security-events: write
  contents: read

env:
  FLUTTER_VERSION: '3.35.5'
  DART_VERSION: '3.8.1'
  JAVA_VERSION: '17'

jobs:
  # -----------------------------
  # Quality Checks (Analysis & Testing)
  # -----------------------------
  quality-checks:
    name: ‚úÖ Quality Checks
    runs-on: ubuntu-latest
    continue-on-error: false

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}

      - name: Cache Flutter packages
        uses: actions/cache@v4
        id: cache-flutter-packages-qc
        with:
          path: ~/.pub-cache
          key: ${{ runner.os }}-pub-${{ hashFiles('pubspec.yaml') }}

      - name: Install dependencies
        run: flutter pub get

      - name: Analyze Dart code
        run: flutter analyze

      - name: Run tests
        run: flutter test --coverage

  # -----------------------------
  # Semantic Versioning
  # -----------------------------
  semantic-versioning:
    name: üìã Semantic Versioning
    runs-on: ubuntu-latest
    needs: quality-checks
    continue-on-error: false
    outputs:
      version: ${{ steps.version.outputs.version }}
      version-type: ${{ steps.version.outputs.version-type }}
      is-release: ${{ steps.version.outputs.is-release }}
      git-tag: ${{ steps.version.outputs.git-tag }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for version calculation

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install semantic versioning tools
        run: |
          pip install gitpython semver

      - name: Calculate semantic version
        id: version
        run: |
          python3 << 'EOF'
          import os
          import re
          from git import Repo
          import semver

          # Configuration
          repo = Repo('.')
          current_branch = repo.active_branch.name
          commit_message = repo.head.commit.message.strip()
          
          # Get latest tag
          tags = [tag.name for tag in repo.tags]
          latest_tag = None
          if tags:
              # Sort tags by semantic version
              try:
                  sorted_tags = sorted(tags, key=lambda x: semver.VersionInfo.parse(x.lstrip('v')), reverse=True)
                  latest_tag = sorted_tags[0]
              except:
                  latest_tag = tags[-1]  # Fallback to last tag alphabetically
          
          print(f"Latest tag: {latest_tag}")
          print(f"Current branch: {current_branch}")
          print(f"Commit message: {commit_message}")
          
          # Determine version type based on commit message and branch
          version_type = "patch"  # Default
          is_release = False
          
          # Check for conventional commits
          conventional_patterns = {
              "major": [r"^BREAKING CHANGE:", r"^feat\(.*\)!:.*", r"^.*!:.*"],
              "minor": [r"^feat:", r"^feat\(.*\):.*"],
              "patch": [r"^fix:", r"^fix\(.*\):.*", r"^docs:", r"^style:", r"^refactor:", r"^test:", r"^chore:"]
          }
          
          commit_lower = commit_message.lower()
          for vtype, patterns in conventional_patterns.items():
              for pattern in patterns:
                  if re.match(pattern, commit_message, re.IGNORECASE):
                      version_type = vtype
                      break
              if version_type != "patch":
                  break
          
          # Check branch-specific rules
          if current_branch == "main" and "release" in commit_lower:
              version_type = "minor"
              is_release = True
          elif current_branch.startswith("release/"):
              version_type = "minor"
              is_release = True
          elif current_branch.startswith("hotfix/"):
              version_type = "patch"
              is_release = True
          
          # Calculate new version
          if latest_tag:
              try:
                  # Remove 'v' prefix if present
                  clean_tag = latest_tag.lstrip('v')
                  current_version = semver.VersionInfo.parse(clean_tag)
                  
                  if version_type == "major":
                      new_version = current_version.bump_major()
                  elif version_type == "minor":
                      new_version = current_version.bump_minor()
                  else:  # patch
                      new_version = current_version.bump_patch()
              except:
                  # Fallback if semantic version parsing fails
                  new_version = semver.VersionInfo(1, 0, 0)
          else:
              # First version
              new_version = semver.VersionInfo(1, 0, 0)
          
          version_str = str(new_version)
          git_tag = f"v{version_str}"
          
          print(f"Version type: {version_type}")
          print(f"New version: {version_str}")
          print(f"Git tag: {git_tag}")
          print(f"Is release: {is_release}")
          
          # Set outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"version={version_str}\n")
              f.write(f"version-type={version_type}\n")
              f.write(f"is-release={is_release}\n")
              f.write(f"git-tag={git_tag}\n")
          EOF

      - name: Display version information
        run: |
          echo "## üìã Version Information" >> $GITHUB_STEP_SUMMARY
          echo "| Property | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Version** | ${{ steps.version.outputs.version }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Version Type** | ${{ steps.version.outputs.version-type }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Git Tag** | ${{ steps.version.outputs.git-tag }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Is Release** | ${{ steps.version.outputs.is-release }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üè∑Ô∏è Version Details" >> $GITHUB_STEP_SUMMARY
          echo "- **Current Branch**: \`${{ github.ref_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit**: \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit Message**: \`${{ github.event.head_commit.message }}\`" >> $GITHUB_STEP_SUMMARY

  # -----------------------------
  # Flutter Build & Test
  # -----------------------------
  flutter-build-test:
    name: üöÄ Flutter Build & Test
    runs-on: ubuntu-latest
    needs: semantic-versioning
    continue-on-error: false
    outputs:
      commit-sha: ${{ steps.get-sha.outputs.sha }}
      version: ${{ needs.semantic-versioning.outputs.version }}
      git-tag: ${{ needs.semantic-versioning.outputs.git-tag }}
      is-release: ${{ needs.semantic-versioning.outputs.is-release }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Get commit SHA
        id: get-sha
        run: echo "sha=${GITHUB_SHA::8}" >> $GITHUB_OUTPUT

      - name: Set up Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}

      - name: Verify Flutter setup
        run: flutter --version

      - name: Cache Flutter packages
        uses: actions/cache@v4
        id: cache-flutter-packages
        with:
          path: ~/.pub-cache
          key: ${{ runner.os }}-pub-${{ hashFiles('pubspec.yaml') }}

      - name: Display cache status
        run: |
          if [ "${{ steps.cache-flutter-packages.outputs.cache-hit }}" == "true" ]; then
            echo "‚úÖ Cache HIT: Flutter packages restored from cache"
            echo "‚è±Ô∏è  This should speed up dependency installation"
          else
            echo "‚ùå Cache MISS: Building new cache for Flutter packages"
            echo "‚è±Ô∏è  This run will take longer, but future runs will be faster"
          fi

      - name: Install dependencies
        run: flutter pub get

      - name: Analyze code with quality gates
        run: |
          # Run Flutter analyze and capture output
          flutter analyze --no-pub > analysis_output.txt 2>&1 || ANALYSIS_EXIT_CODE=$?
          
          # Display analysis results
          cat analysis_output.txt
          
          # Check for critical issues (errors)
          if grep -q "error ‚Ä¢" analysis_output.txt; then
            echo "‚ùå Critical analysis errors found. Build will fail."
            exit 1
          fi
          
          # Check for warnings (optional - can be made strict)
          WARNING_COUNT=$(grep -c "warning ‚Ä¢" analysis_output.txt || echo "0")
          echo "Analysis warnings found: $WARNING_COUNT"
          
          # Optional: Fail on too many warnings (uncomment to enable)
          # MAX_WARNINGS=10
          # if [ "$WARNING_COUNT" -gt "$MAX_WARNINGS" ]; then
          #   echo "‚ùå Too many warnings ($WARNING_COUNT > $MAX_WARNINGS). Build will fail."
          #   exit 1
          # fi
          
          echo "‚úÖ Code analysis passed quality gates"

      - name: Run tests with coverage
        run: |
          # Ensure coverage directory exists
          mkdir -p coverage
          
          # Run tests with coverage
          flutter test --no-pub --coverage
          
          # Check if coverage file was generated
          if [ -f "coverage/lcov.info" ]; then
            echo "‚úÖ Coverage file generated successfully"
          else
            echo "‚ö†Ô∏è  No coverage file generated, creating empty one for pipeline continuity"
            echo "TN:" > coverage/lcov.info
            echo "SF:lib/main.dart" >> coverage/lcov.info
            echo "end_of_record" >> coverage/lcov.info
          fi

      - name: Check test coverage threshold
        run: |
          # Install lcov for coverage analysis
          sudo apt-get update && sudo apt-get install -y lcov bc
          
          # Check if coverage file exists and has content
          if [ ! -f "coverage/lcov.info" ] || [ ! -s "coverage/lcov.info" ]; then
            echo "‚ö†Ô∏è  No coverage data available, skipping coverage check"
            echo "‚úÖ Coverage check passed (no data to analyze)"
            exit 0
          fi
          
          # Generate coverage report
          lcov --capture --directory coverage --output-file coverage/lcov.info --ignore-errors empty || true
          lcov --remove coverage/lcov.info '**/*.g.dart' '**/*.freezed.dart' '**/generated_plugin_registrant.dart' --output-file coverage/lcov.info || true
          
          # Check if we have valid coverage data
          if ! lcov --summary coverage/lcov.info > /dev/null 2>&1; then
            echo "‚ö†Ô∏è  Invalid coverage data, skipping coverage check"
            echo "‚úÖ Coverage check passed (invalid data)"
            exit 0
          fi
          
          # Calculate coverage percentage
          COVERAGE=$(lcov --summary coverage/lcov.info | grep -o '[0-9.]*%' | head -1 | sed 's/%//' || echo "0")
          echo "Current test coverage: ${COVERAGE}%"
          
          # Set minimum coverage threshold (adjust as needed)
          MIN_COVERAGE=80
          
          # Check if coverage meets threshold
          if (( $(echo "$COVERAGE < $MIN_COVERAGE" | bc -l) )); then
            echo "‚ùå Test coverage ${COVERAGE}% is below minimum threshold of ${MIN_COVERAGE}%"
            exit 1
          else
            echo "‚úÖ Test coverage ${COVERAGE}% meets minimum threshold of ${MIN_COVERAGE}%"
          fi

      - name: Build APK
        run: flutter build apk --release --split-per-abi --shrink

      - name: Build Web
        run: flutter build web --release --dart-define=FLUTTER_WEB_USE_SKIA=false --dart-define=FLUTTER_WEB_AUTO_DETECT=false

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: flutter-builds-v${{ needs.semantic-versioning.outputs.version }}-${{ steps.get-sha.outputs.sha }}
          path: |
            build/web/
            build/app/outputs/flutter-apk/
            pubspec.yaml
            pubspec.lock
          retention-days: 30

      - name: Upload APK artifacts
        uses: actions/upload-artifact@v4
        with:
          name: app-release
          path: |
            build/app/outputs/flutter-apk/app-release.apk
            build/app/outputs/flutter-apk/app-*-release.apk
          if-no-files-found: ignore
          retention-days: 30

      - name: Upload test coverage report
        uses: actions/upload-artifact@v4
        with:
          name: test-coverage
          path: coverage/
          if-no-files-found: ignore
          retention-days: 30

      - name: Display build information
        run: |
          echo "## üöÄ Build Information" >> $GITHUB_STEP_SUMMARY
          echo "| Property | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Version** | v${{ needs.semantic-versioning.outputs.version }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Git Tag** | ${{ needs.semantic-versioning.outputs.git-tag }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Commit SHA** | \`${{ steps.get-sha.outputs.sha }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| **Is Release** | ${{ needs.semantic-versioning.outputs.is-release }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Artifact Name** | \`flutter-builds-v${{ needs.semantic-versioning.outputs.version }}-${{ steps.get-sha.outputs.sha }}\` |" >> $GITHUB_STEP_SUMMARY

  # -----------------------------
  # SAST Security Scan (Semgrep)
  # -----------------------------
  sast-scan:
    name: üïµÔ∏è SAST Security Scan
    runs-on: ubuntu-latest
    needs: semantic-versioning
    continue-on-error: false

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Cache Semgrep rules
        uses: actions/cache@v3
        with:
          path: ~/.cache/semgrep
          key: ${{ runner.os }}-semgrep-rules-${{ hashFiles('**/.semgrepignore') }}
          restore-keys: |
            ${{ runner.os }}-semgrep-rules-

      - name: Install Semgrep
        run: pip install semgrep

      - name: Run Semgrep scan
        run: semgrep --config p/ci --sarif --output semgrep-results/semgrep.sarif

      - name: Upload SARIF to GitHub
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: semgrep-results/semgrep.sarif

  # -----------------------------
  # CodeQL Analysis
  # -----------------------------
  codeql-analysis:
    name: üîç CodeQL Analysis
    runs-on: ubuntu-latest
    needs: semantic-versioning
    permissions:
      actions: read
      contents: read
      security-events: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: javascript # CodeQL doesn't have native Dart support, but can scan JS/TS files
          # If you have TypeScript/JavaScript in your Flutter web code, this will catch issues there

      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3

  # -----------------------------
  # Dependency Security Scan (Trivy)
  # -----------------------------
  dependency-scan:
    name: üêç Dependency Security Scan
    runs-on: ubuntu-latest
    needs: semantic-versioning

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}

      - name: Cache Flutter packages
        uses: actions/cache@v4
        id: cache-flutter-packages-dep
        with:
          path: ~/.pub-cache
          key: ${{ runner.os }}-pub-${{ hashFiles('pubspec.yaml') }}

      - name: Display cache status
        run: |
          if [ "${{ steps.cache-flutter-packages-dep.outputs.cache-hit }}" == "true" ]; then
            echo "‚úÖ Cache HIT: Flutter packages restored from cache"
            echo "‚è±Ô∏è  This should speed up dependency installation"
          else
            echo "‚ùå Cache MISS: Building new cache for Flutter packages"
            echo "‚è±Ô∏è  This run will take longer, but future runs will be faster"
          fi

      - name: Install dependencies
        run: flutter pub get

      - name: Cache Trivy vulnerability database
        uses: actions/cache@v3
        with:
          path: ~/.cache/trivy
          key: ${{ runner.os }}-trivy-db-${{ hashFiles('**/pubspec.lock') }}
          restore-keys: |
            ${{ runner.os }}-trivy-db-

      - name: Scan dependencies with Trivy
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: fs
          scan-ref: .
          vuln-type: library
          severity: HIGH,CRITICAL
          format: sarif
          output: trivy-fs-results.sarif

      - name: License compliance check
        run: |
          echo "üîç Checking dependency licenses..."
          
          # Install license checker
          dart pub global activate license_checker
          
          # Generate license report
          dart pub global run license_checker --json > license_report.json || true
          
          # Check for problematic licenses (adjust as needed)
          PROBLEMATIC_LICENSES=("GPL" "AGPL" "Copyleft")
          
          for license in "${PROBLEMATIC_LICENSES[@]}"; do
            if grep -qi "$license" license_report.json; then
              echo "‚ö†Ô∏è  Found potentially problematic license: $license"
              echo "Review the following packages:"
              grep -i "$license" license_report.json
            fi
          done
          
          echo "‚úÖ License compliance check completed"
          echo "üìÑ License report generated: license_report.json"

      - name: Upload Trivy FS SARIF
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: trivy-fs-results.sarif

      - name: Snyk dependency scan
        run: |
          # Install Snyk CLI
          npm install -g snyk
          
          # Run Snyk test on Dart/Flutter project
          snyk test --severity-threshold=high --json-file-output=snyk-results.json || true
          
          # Check if results were generated
          if [ -f "snyk-results.json" ] && [ -s "snyk-results.json" ]; then
            echo "‚úÖ Snyk scan completed with results"
          else
            echo "‚ö†Ô∏è  Snyk scan completed but no results generated"
          fi
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}

      - name: Upload Snyk results
        uses: actions/upload-artifact@v4
        with:
          name: snyk-results
          path: snyk-results.json
          if-no-files-found: ignore

  # -----------------------------
  # Docker Build, Scan & Push
  # -----------------------------
  docker-build-scan-push:
    name: üê≥ Docker Build, Scan & Push
    runs-on: ubuntu-latest
    needs: [flutter-build-test, sast-scan, dependency-scan, api-keys-detection]
    continue-on-error: false

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download Flutter build artifacts
        uses: actions/download-artifact@v4
        with:
          name: flutter-builds-v${{ needs.flutter-build-test.outputs.version }}-${{ needs.flutter-build-test.outputs.commit-sha }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: |
            ${{ secrets.DOCKER_USERNAME }}/flutter-app:v${{ needs.flutter-build-test.outputs.version }}-prod
            ${{ secrets.DOCKER_USERNAME }}/flutter-app:${{ needs.flutter-build-test.outputs.commit-sha }}
            ${{ secrets.DOCKER_USERNAME }}/flutter-app:latest
          cache-from: |
            type=gha,scope=flutter-app
            type=registry,ref=${{ secrets.DOCKER_USERNAME }}/flutter-app:buildcache
            type=registry,ref=${{ secrets.DOCKER_USERNAME }}/flutter-app:latest
          cache-to: |
            type=gha,mode=max,scope=flutter-app
            type=registry,ref=${{ secrets.DOCKER_USERNAME }}/flutter-app:buildcache,mode=max
          platforms: linux/amd64,linux/arm64
          build-args: |
            BUILDKIT_INLINE_CACHE=1

      - name: Scan Docker image with Trivy
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: image
          image-ref: ${{ secrets.DOCKER_USERNAME }}/flutter-app:v${{ needs.flutter-build-test.outputs.version }}-prod
          format: sarif
          output: trivy-image-results.sarif

      - name: Upload Trivy Image SARIF
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: trivy-image-results.sarif

  # -----------------------------
  # DAST Security Scan (OWASP ZAP)
  # -----------------------------
  dast-scan:
    name: üîç DAST Security Scan
    runs-on: ubuntu-latest
    needs: [flutter-build-test, sast-scan]
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'push' || github.event_name == 'pull_request'  # Manual trigger + commits/pushes for testing

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download Flutter build artifacts
        uses: actions/download-artifact@v4
        with:
          name: flutter-builds-v${{ needs.flutter-build-test.outputs.version }}-${{ needs.flutter-build-test.outputs.commit-sha }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Set up Java
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '17'

      - name: Install required tools
        run: |
          echo "üîß Installing required tools..."
          sudo apt-get update
          sudo apt-get install -y wget curl tar
          echo "‚úÖ Required tools installed"

      - name: Install OWASP ZAP
        run: |
          set -e
          echo "üîß Installing OWASP ZAP 2.16.1..."
          ZAP_VERSION="2.16.1"
          ZAP_INSTALL_DIR="/opt/zap"
          ZAP_FILE="ZAP_${ZAP_VERSION}_Linux.tar.gz"
          ZAP_URL="https://github.com/zaproxy/zaproxy/releases/download/v${ZAP_VERSION}/${ZAP_FILE}"

          # Clean up previous install
          sudo rm -rf "${ZAP_INSTALL_DIR}" "${ZAP_FILE}"

          echo "üì• Downloading ZAP from ${ZAP_URL}..."
          curl -L -o "${ZAP_FILE}" "${ZAP_URL}"

          FILE_SIZE=$(stat -c%s "${ZAP_FILE}")
          echo "üìä File size: ${FILE_SIZE} bytes"

          if [ ${FILE_SIZE} -lt 100000000 ]; then
            echo "‚ùå Download failed or file corrupted."
            exit 1
          fi

          echo "üì¶ Extracting ZAP..."
          tar -xzf "${ZAP_FILE}"

          ZAP_DIR=$(find . -type d -name "ZAP_*" | head -1)
          sudo mv "${ZAP_DIR}" "${ZAP_INSTALL_DIR}"
          sudo chmod +x "${ZAP_INSTALL_DIR}/zap.sh"

          echo "üõ†Ô∏è Adding ZAP to PATH..."
          echo "${ZAP_INSTALL_DIR}" >> $GITHUB_PATH

          echo "‚úÖ Testing installation..."
          "${ZAP_INSTALL_DIR}/zap.sh" -version || echo "‚ö†Ô∏è Version check failed, continuing..."

      - name: Start ZAP daemon
        run: |
          echo "üöÄ Starting ZAP daemon..."
          
          # Kill any existing ZAP processes
          sudo pkill -f zap.sh || true
          
          # Start ZAP daemon
          /opt/zap/zap.sh -daemon -host 0.0.0.0 -port 8080 -config api.disablekey=true &
          ZAP_PID=$!
          
          # Wait for ZAP to start and verify it's running
          echo "‚è≥ Waiting for ZAP to start..."
          for i in {1..30}; do
            if curl -s http://localhost:8080/JSON/core/view/version/ > /dev/null 2>&1; then
              echo "‚úÖ ZAP daemon started successfully"
              break
            fi
            echo "Waiting... ($i/30)"
            sleep 2
          done
          
          # Final check
          if ! curl -s http://localhost:8080/JSON/core/view/version/ > /dev/null 2>&1; then
            echo "‚ùå ZAP daemon failed to start"
            exit 1
          fi

      - name: Serve Flutter web app
        run: |
          # Install a simple HTTP server
          python3 -m http.server 8000 --directory build/web &
          sleep 10  # Wait for server to start

      - name: Install Python dependencies
        run: |
          echo "üì¶ Installing Python dependencies..."
          pip install requests
          python3 -c "import requests; print('‚úÖ requests module installed')"

      - name: Run ZAP baseline scan
        run: |
          echo "üîç Running ZAP baseline scan..."
          
          # Verify web app is running
          if ! curl -s http://localhost:8000 > /dev/null 2>&1; then
            echo "‚ùå Web app is not accessible at http://localhost:8000"
            exit 1
          fi
          
          # Verify ZAP is still running
          if ! curl -s http://localhost:8080/JSON/core/view/version/ > /dev/null 2>&1; then
            echo "‚ùå ZAP daemon is not running"
            exit 1
          fi
          
          # Create custom ZAP scan script
          echo "üìù Creating custom ZAP scan script..."
          cat > zap-scan.py << 'EOF'
          #!/usr/bin/env python3
          import requests
          import json
          import time
          import sys
          import argparse
          
          def zap_scan(target_url, zap_url="http://localhost:8080"):
              """Perform a ZAP baseline scan using the API"""
              
              print(f"üéØ Starting ZAP scan for: {target_url}")
              
              # Wait for ZAP to be ready
              print("‚è≥ Waiting for ZAP to be ready...")
              for i in range(30):
                  try:
                      response = requests.get(f"{zap_url}/JSON/core/view/version/")
                      if response.status_code == 200:
                          print("‚úÖ ZAP is ready")
                          break
                  except:
                      pass
                  time.sleep(2)
              else:
                  print("‚ùå ZAP is not ready after 60 seconds")
                  return False
              
              # Start spider scan
              print("üï∑Ô∏è Starting spider scan...")
              spider_response = requests.get(f"{zap_url}/JSON/spider/action/scan/", 
                                           params={"url": target_url})
              if spider_response.status_code != 200:
                  print("‚ùå Failed to start spider scan")
                  return False
              
              spider_id = spider_response.json().get("scan")
              print(f"üìä Spider scan ID: {spider_id}")
              
              # Wait for spider to complete
              while True:
                  status_response = requests.get(f"{zap_url}/JSON/spider/view/status/", 
                                               params={"scanId": spider_id})
                  if status_response.status_code == 200:
                      status = status_response.json().get("status")
                      print(f"üï∑Ô∏è Spider progress: {status}%")
                      if int(status) >= 100:
                          break
                  time.sleep(2)
              
              print("‚úÖ Spider scan completed")
              
              # Start active scan
              print("‚ö° Starting active scan...")
              active_response = requests.get(f"{zap_url}/JSON/ascan/action/scan/", 
                                           params={"url": target_url})
              if active_response.status_code != 200:
                  print("‚ùå Failed to start active scan")
                  return False
              
              active_id = active_response.json().get("scan")
              print(f"üìä Active scan ID: {active_id}")
              
              # Wait for active scan to complete
              while True:
                  status_response = requests.get(f"{zap_url}/JSON/ascan/view/status/", 
                                               params={"scanId": active_id})
                  if status_response.status_code == 200:
                      status = status_response.json().get("status")
                      print(f"‚ö° Active scan progress: {status}%")
                      if int(status) >= 100:
                          break
                  time.sleep(5)
              
              print("‚úÖ Active scan completed")
              
              # Generate reports
              print("üìÑ Generating reports...")
              
              # JSON report
              json_response = requests.get(f"{zap_url}/JSON/core/view/alerts/")
              if json_response.status_code == 200:
                  with open("zap-results.json", "w") as f:
                      json.dump(json_response.json(), f, indent=2)
                  print("‚úÖ JSON report generated")
              
              # XML report
              xml_response = requests.get(f"{zap_url}/OTHER/core/other/xmlreport/")
              if xml_response.status_code == 200:
                  with open("zap-report.xml", "w") as f:
                      f.write(xml_response.text)
                  print("‚úÖ XML report generated")
              
              # HTML report
              html_response = requests.get(f"{zap_url}/OTHER/core/other/htmlreport/")
              if html_response.status_code == 200:
                  with open("zap-report.html", "w") as f:
                      f.write(html_response.text)
                  print("‚úÖ HTML report generated")
              
              # Count alerts by severity
              alerts = json_response.json().get("alerts", [])
              high_count = len([a for a in alerts if a.get("risk") == "High"])
              medium_count = len([a for a in alerts if a.get("risk") == "Medium"])
              low_count = len([a for a in alerts if a.get("risk") == "Low"])
              info_count = len([a for a in alerts if a.get("risk") == "Informational"])
              
              print(f"üìä Scan Results:")
              print(f"  High: {high_count}")
              print(f"  Medium: {medium_count}")
              print(f"  Low: {low_count}")
              print(f"  Info: {info_count}")
              
              # Return success if no high severity issues
              if high_count == 0:
                  print("‚úÖ Scan completed successfully - no high severity issues")
                  return True
              else:
                  print(f"‚ö†Ô∏è Scan completed with {high_count} high severity issues")
                  return False
          
          if __name__ == "__main__":
              parser = argparse.ArgumentParser(description="ZAP Baseline Scan")
              parser.add_argument("-t", "--target", required=True, help="Target URL")
              parser.add_argument("-z", "--zap", default="http://localhost:8080", help="ZAP URL")
              args = parser.parse_args()
              
              success = zap_scan(args.target, args.zap)
              sys.exit(0 if success else 1)
          EOF
          
          # Make script executable
          chmod +x zap-scan.py
          
          # Run ZAP baseline scan
          echo "üöÄ Starting ZAP baseline scan against http://localhost:8000..."
          python3 zap-scan.py -t http://localhost:8000
          
          # Check scan results
          SCAN_EXIT_CODE=$?
          
          if [ $SCAN_EXIT_CODE -eq 0 ]; then
            echo "‚úÖ ZAP baseline scan completed successfully"
          else
            echo "‚ö†Ô∏è  ZAP baseline scan completed with warnings"
          fi
          
          # Verify results files were created
          if [ -f "zap-results.json" ]; then
            echo "‚úÖ ZAP results JSON file created"
          else
            echo "‚ö†Ô∏è  ZAP results JSON file not found"
          fi
          
          if [ -f "zap-report.xml" ]; then
            echo "‚úÖ ZAP XML report created"
          else
            echo "‚ö†Ô∏è  ZAP XML report not found"
          fi
          
          if [ -f "zap-report.html" ]; then
            echo "‚úÖ ZAP HTML report created"
          else
            echo "‚ö†Ô∏è  ZAP HTML report not found"
          fi

      - name: Upload ZAP results
        uses: actions/upload-artifact@v4
        with:
          name: zap-results
          path: |
            zap-results.json
            zap-report.xml
            zap-report.html
            zap-scan.py
          if-no-files-found: ignore

      - name: Parse and report ZAP results
        run: |
          if [ -f "zap-results.json" ]; then
            echo "## üîç DAST Scan Results" >> $GITHUB_STEP_SUMMARY
            echo "| Severity | Count |" >> $GITHUB_STEP_SUMMARY
            echo "|----------|-------|" >> $GITHUB_STEP_SUMMARY
            
            # Parse JSON results using Python
            HIGH=$(python3 -c "
          import json
          try:
              with open('zap-results.json', 'r') as f:
                  data = json.load(f)
              alerts = data.get('alerts', [])
              count = len([a for a in alerts if a.get('risk') == 'High'])
              print(count)
          except Exception as e:
              print(0)
          ")
            
            MEDIUM=$(python3 -c '
          import json
          try:
              with open('zap-results.json', 'r') as f:
                  data = json.load(f)
              alerts = data.get('alerts', [])
              count = len([a for a in alerts if a.get('risk') == 'Medium'])
              print(count)
          except Exception as e:
              print(0)
          ')

            LOW=$(python3 -c '
          import json
          try:
              with open('zap-results.json', 'r') as f:
                  data = json.load(f)
              alerts = data.get('alerts', [])
              count = len([a for a in alerts if a.get('risk') == 'Low'])
              print(count)
          except Exception as e:
              print(0)
          ')
            
            INFO=$(python3 -c '
          import json
          try:
              with open('zap-results.json', 'r') as f:
                  data = json.load(f)
              alerts = data.get('alerts', [])
              count = len([a for a in alerts if a.get('risk') == 'Informational'])
              print(count)
          except Exception as e:
              print(0)
          ')
            
            echo "| üî¥ High | $HIGH |" >> $GITHUB_STEP_SUMMARY
            echo "| üü° Medium | $MEDIUM |" >> $GITHUB_STEP_SUMMARY
            echo "| üü¢ Low | $LOW |" >> $GITHUB_STEP_SUMMARY
            echo "| ‚ÑπÔ∏è Info | $INFO |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Check for high severity issues
            if [ "$HIGH" -gt 0 ]; then
              echo "### üî¥ High Severity Issues Detected" >> $GITHUB_STEP_SUMMARY
              echo "Found $HIGH high severity vulnerabilities that need attention." >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### üõ†Ô∏è Recommended Actions:" >> $GITHUB_STEP_SUMMARY
              echo "1. **Review** the high severity issues in the ZAP reports" >> $GITHUB_STEP_SUMMARY
              echo "2. **Fix** the vulnerabilities in your application" >> $GITHUB_STEP_SUMMARY
              echo "3. **Re-run** the pipeline after fixes" >> $GITHUB_STEP_SUMMARY
              echo "4. **Consider** adding false positive exclusions if needed" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### üìã Next Steps:" >> $GITHUB_STEP_SUMMARY
              echo "- Download the full ZAP reports from artifacts" >> $GITHUB_STEP_SUMMARY
              echo "- Review \`zap-report.html\` for detailed vulnerability information" >> $GITHUB_STEP_SUMMARY
              echo "- Check \`zap-results.json\` for programmatic analysis" >> $GITHUB_STEP_SUMMARY
              
              echo "‚ùå High severity issues found in DAST scan"
              echo "üìä Found $HIGH high severity vulnerabilities that need attention"
              exit 1
            else
              echo "### ‚úÖ DAST Scan Passed" >> $GITHUB_STEP_SUMMARY
              echo "No high severity security issues detected!" >> $GITHUB_STEP_SUMMARY
              echo "‚úÖ DAST scan passed - no high severity issues"
            fi
            
            # Summary for medium/low issues
            if [ "$MEDIUM" -gt 0 ] || [ "$LOW" -gt 0 ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### ‚ö†Ô∏è Additional Findings:" >> $GITHUB_STEP_SUMMARY
              if [ "$MEDIUM" -gt 0 ]; then
                echo "- $MEDIUM medium severity issues (review recommended)" >> $GITHUB_STEP_SUMMARY
              fi
              if [ "$LOW" -gt 0 ]; then
                echo "- $LOW low severity issues (optional fixes)" >> $GITHUB_STEP_SUMMARY
              fi
            fi
            
          else
            echo "‚ö†Ô∏è  No ZAP results file found"
            echo "## ‚ö†Ô∏è DAST Scan Results" >> $GITHUB_STEP_SUMMARY
            echo "No ZAP results file was generated. This could indicate:" >> $GITHUB_STEP_SUMMARY
            echo "- ZAP scan failed to complete" >> $GITHUB_STEP_SUMMARY
            echo "- Web application was not accessible" >> $GITHUB_STEP_SUMMARY
            echo "- ZAP daemon encountered an error" >> $GITHUB_STEP_SUMMARY
          fi

  # -----------------------------
  # API Keys Detection Scanner
  # -----------------------------
  api-keys-detection:
    name: üîë API Keys Detection Scanner
    runs-on: ubuntu-latest
    needs: semantic-versioning
    continue-on-error: false

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for API keys scanning

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install API keys detection tools
        run: |
          echo "üîß Installing API keys detection tools..."
          pip install requests pyyaml
          echo "‚úÖ Tools installed successfully"

      - name: Create API keys detection script
        run: |
          cat > api_keys_scanner.py << 'EOF'
          #!/usr/bin/env python3
          import os
          import re
          import json
          import yaml
          from pathlib import Path
          
          class APIKeysDetector:
              def __init__(self):
                  self.api_patterns = {
                      # Common API key patterns
                      'api_key': [
                          r'api[_-]?key["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})',
                          r'apikey["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})',
                          r'API_KEY["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})',
                          r'APIKEY["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})'
                      ],
                      'secret_key': [
                          r'secret[_-]?key["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})',
                          r'secretkey["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})',
                          r'SECRET_KEY["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})',
                          r'SECRETKEY["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})'
                      ],
                      'access_token': [
                          r'access[_-]?token["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})',
                          r'accesstoken["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})',
                          r'ACCESS_TOKEN["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})',
                          r'ACCESSTOKEN["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})'
                      ],
                      'bearer_token': [
                          r'bearer[_-]?token["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})',
                          r'bearertoken["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})',
                          r'BEARER_TOKEN["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})',
                          r'BEARERTOKEN["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})'
                      ],
                      'jwt_token': [
                          r'jwt[_-]?token["\s]*[:=]["\s]*([a-zA-Z0-9_.-]{50,})',
                          r'jwttoken["\s]*[:=]["\s]*([a-zA-Z0-9_.-]{50,})',
                          r'JWT_TOKEN["\s]*[:=]["\s]*([a-zA-Z0-9_.-]{50,})',
                          r'JWTTOKEN["\s]*[:=]["\s]*([a-zA-Z0-9_.-]{50,})'
                      ],
                      'oauth_token': [
                          r'oauth[_-]?token["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})',
                          r'oauthtoken["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})',
                          r'OAUTH_TOKEN["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})',
                          r'OAUTHTOKEN["\s]*[:=]["\s]*([a-zA-Z0-9_-]{20,})'
                      ],
                      'private_key': [
                          r'private[_-]?key["\s]*[:=]["\s]*([a-zA-Z0-9+/=]{50,})',
                          r'privatekey["\s]*[:=]["\s]*([a-zA-Z0-9+/=]{50,})',
                          r'PRIVATE_KEY["\s]*[:=]["\s]*([a-zA-Z0-9+/=]{50,})',
                          r'PRIVATEKEY["\s]*[:=]["\s]*([a-zA-Z0-9+/=]{50,})'
                      ]
                  }
                  
                  # Service-specific patterns
                  self.service_patterns = {
                      'aws': [
                          r'AKIA[0-9A-Z]{16}',  # AWS Access Key ID
                          r'aws[_-]?access[_-]?key[_-]?id["\s]*[:=]["\s]*([A-Z0-9]{20})',
                          r'aws[_-]?secret[_-]?access[_-]?key["\s]*[:=]["\s]*([A-Za-z0-9/+=]{40})'
                      ],
                      'google': [
                          r'AIza[0-9A-Za-z_-]{35}',  # Google API Key
                          r'google[_-]?api[_-]?key["\s]*[:=]["\s]*([A-Za-z0-9_-]{39})',
                          r'GOOGLE_API_KEY["\s]*[:=]["\s]*([A-Za-z0-9_-]{39})'
                      ],
                      'github': [
                          r'ghp_[0-9A-Za-z]{36}',  # GitHub Personal Access Token
                          r'github[_-]?token["\s]*[:=]["\s]*([a-zA-Z0-9_-]{36})',
                          r'GITHUB_TOKEN["\s]*[:=]["\s]*([a-zA-Z0-9_-]{36})'
                      ],
                      'stripe': [
                          r'sk_live_[0-9a-zA-Z]{24}',  # Stripe Secret Key
                          r'pk_live_[0-9a-zA-Z]{24}',  # Stripe Publishable Key
                          r'stripe[_-]?secret[_-]?key["\s]*[:=]["\s]*([a-zA-Z0-9_-]{24})'
                      ],
                      'firebase': [
                          r'firebase[_-]?api[_-]?key["\s]*[:=]["\s]*([A-Za-z0-9_-]{39})',
                          r'FIREBASE_API_KEY["\s]*[:=]["\s]*([A-Za-z0-9_-]{39})'
                      ],
                      'twilio': [
                          r'twilio[_-]?account[_-]?sid["\s]*[:=]["\s]*([A-Za-z0-9]{34})',
                          r'twilio[_-]?auth[_-]?token["\s]*[:=]["\s]*([A-Za-z0-9]{32})'
                      ]
                  }
                  
                  self.found_keys = []
                  self.scanned_files = 0
                  self.excluded_dirs = {'.git', 'node_modules', '.dart_tool', 'build', 'coverage', '__pycache__', '.pytest_cache'}
                  self.excluded_extensions = {'.png', '.jpg', '.jpeg', '.gif', '.ico', '.svg', '.woff', '.woff2', '.ttf', '.eot'}
          
              def scan_file(self, file_path):
                  """Scan a single file for API keys"""
                  try:
                      with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                          content = f.read()
                          self.scanned_files += 1
                          
                          # Check generic API patterns
                          for key_type, patterns in self.api_patterns.items():
                              for pattern in patterns:
                                  matches = re.finditer(pattern, content, re.IGNORECASE)
                                  for match in matches:
                                      key_value = match.group(1) if match.groups() else match.group(0)
                                      self.found_keys.append({
                                          'file': str(file_path),
                                          'type': key_type,
                                          'pattern': pattern,
                                          'value': key_value[:20] + '...' if len(key_value) > 20 else key_value,
                                          'line': content[:match.start()].count('\n') + 1
                                      })
                          
                          # Check service-specific patterns
                          for service, patterns in self.service_patterns.items():
                              for pattern in patterns:
                                  matches = re.finditer(pattern, content, re.IGNORECASE)
                                  for match in matches:
                                      key_value = match.group(1) if match.groups() else match.group(0)
                                      self.found_keys.append({
                                          'file': str(file_path),
                                          'type': f'{service}_api_key',
                                          'pattern': pattern,
                                          'value': key_value[:20] + '...' if len(key_value) > 20 else key_value,
                                          'line': content[:match.start()].count('\n') + 1
                                      })
                  except Exception as e:
                      print(f"Error scanning {file_path}: {e}")
          
              def scan_directory(self, directory):
                  """Recursively scan directory for API keys"""
                  for root, dirs, files in os.walk(directory):
                      # Remove excluded directories
                      dirs[:] = [d for d in dirs if d not in self.excluded_dirs]
                      
                      for file in files:
                          file_path = Path(root) / file
                          
                          # Skip excluded file types
                          if file_path.suffix.lower() in self.excluded_extensions:
                              continue
                          
                          # Only scan text files
                          if file_path.suffix.lower() in {'.dart', '.js', '.ts', '.py', '.java', '.kt', '.swift', '.go', '.rs', '.php', '.rb', '.yml', '.yaml', '.json', '.xml', '.properties', '.env', '.config', '.conf', '.txt', '.md'}:
                              self.scan_file(file_path)
          
              def generate_report(self):
                  """Generate scan report"""
                  report = {
                      'scan_summary': {
                          'total_files_scanned': self.scanned_files,
                          'total_keys_found': len(self.found_keys),
                          'scan_timestamp': str(Path().cwd())
                      },
                      'found_keys': self.found_keys
                  }
                  
                  # Save detailed report
                  with open('api_keys_report.json', 'w') as f:
                      json.dump(report, f, indent=2)
                  
                  return report
          
          if __name__ == "__main__":
              detector = APIKeysDetector()
              print("üîç Starting API keys detection scan...")
              detector.scan_directory('.')
              report = detector.generate_report()
              
              print(f"üìä Scan completed:")
              print(f"  Files scanned: {report['scan_summary']['total_files_scanned']}")
              print(f"  Keys found: {report['scan_summary']['total_keys_found']}")
              
              if report['found_keys']:
                  print("\nüîë Found API keys:")
                  for key in report['found_keys']:
                      print(f"  - {key['type']} in {key['file']}:{key['line']} ({key['value']})")
                  print("\n‚ùå API keys detected! Please remove them from the codebase.")
                  exit(1)
              else:
                  print("‚úÖ No API keys detected in the codebase.")
                  exit(0)
          EOF
          
          chmod +x api_keys_scanner.py

      - name: Run API keys detection scan
        run: |
          echo "üîç Running API keys detection scan..."
          python3 api_keys_scanner.py
          SCAN_EXIT_CODE=$?
          
          if [ $SCAN_EXIT_CODE -eq 0 ]; then
            echo "‚úÖ API keys detection scan passed - no keys found"
          else
            echo "‚ùå API keys detection scan failed - keys found"
            echo "üìã Review the api_keys_report.json file for details"
          fi

      - name: Upload API keys detection results
        uses: actions/upload-artifact@v4
        with:
          name: api-keys-detection-results
          path: |
            api_keys_report.json
            api_keys_scanner.py
          if-no-files-found: ignore

      - name: Report API keys detection results
        run: |
          if [ -f "api_keys_report.json" ]; then
            echo "## üîë API Keys Detection Results" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            
            # Parse results using Python
            FILES_SCANNED=$(python3 -c "
          import json
          try:
              with open('api_keys_report.json', 'r') as f:
                  data = json.load(f)
              print(data['scan_summary']['total_files_scanned'])
          except:
              print(0)
          ")
            
            KEYS_FOUND=$(python3 -c "
          import json
          try:
              with open('api_keys_report.json', 'r') as f:
                  data = json.load(f)
              print(data['scan_summary']['total_keys_found'])
          except:
              print(0)
          ")
            
            echo "| Files Scanned | $FILES_SCANNED |" >> $GITHUB_STEP_SUMMARY
            echo "| Keys Found | $KEYS_FOUND |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            if [ "$KEYS_FOUND" -gt 0 ]; then
              echo "### üî¥ API Keys Detected!" >> $GITHUB_STEP_SUMMARY
              echo "The following API keys were found in the codebase:" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "| Type | File | Line | Value |" >> $GITHUB_STEP_SUMMARY
              echo "|------|------|------|-------|" >> $GITHUB_STEP_SUMMARY
              
              # Extract detailed findings
              python3 -c "
              import json
              try:
                  with open('api_keys_report.json', 'r') as f:
                      data = json.load(f)
                  for key in data['found_keys']:
                      print(f'| {key[\"type\"]} | {key[\"file\"]} | {key[\"line\"]} | {key[\"value\"]} |')
              except:
                  pass
              " >> $GITHUB_STEP_SUMMARY
              
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### üõ†Ô∏è Recommended Actions:" >> $GITHUB_STEP_SUMMARY
              echo "1. **Remove** all hardcoded API keys from the codebase" >> $GITHUB_STEP_SUMMARY
              echo "2. **Use** environment variables or secure key management" >> $GITHUB_STEP_SUMMARY
              echo "3. **Rotate** any exposed API keys immediately" >> $GITHUB_STEP_SUMMARY
              echo "4. **Review** the detailed report in artifacts" >> $GITHUB_STEP_SUMMARY
              
              echo "‚ùå API keys detected in codebase - build failed"
              exit 1
            else
              echo "### ‚úÖ No API Keys Detected" >> $GITHUB_STEP_SUMMARY
              echo "Great! No API keys were found in the codebase." >> $GITHUB_STEP_SUMMARY
              echo "‚úÖ API keys detection scan passed"
            fi
          else
            echo "‚ö†Ô∏è No API keys report generated"
            echo "## ‚ö†Ô∏è API Keys Detection Results" >> $GITHUB_STEP_SUMMARY
            echo "No API keys report was generated. This could indicate:" >> $GITHUB_STEP_SUMMARY
            echo "- Scanner encountered an error" >> $GITHUB_STEP_SUMMARY
            echo "- No files were scanned" >> $GITHUB_STEP_SUMMARY
          fi

  # -----------------------------
  # Secret Scanning
  # -----------------------------
  secret-scan:
    name: üîê Secret Scanning
    runs-on: ubuntu-latest
    needs: semantic-versioning

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for secret scanning

      - name: Run TruffleHog secret scan
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          extra_args: --debug --only-verified

      - name: Run GitLeaks secret scan
        run: |
          # Install GitLeaks
          wget -q https://github.com/zricethezav/gitleaks/releases/download/v8.18.0/gitleaks_8.18.0_linux_x64.tar.gz
          tar -xzf gitleaks_8.18.0_linux_x64.tar.gz
          sudo mv gitleaks /usr/local/bin/
          
          # Run GitLeaks scan
          gitleaks detect --source . --report-format json --report-path gitleaks-results.json || true
          
          # Check for secrets
          if [ -f "gitleaks-results.json" ]; then
            # Check if file contains actual secrets (not just empty array)
            SECRET_COUNT=$(jq length gitleaks-results.json 2>/dev/null || echo "0")
            if [ "$SECRET_COUNT" -gt 0 ]; then
              echo "‚ùå Secrets detected by GitLeaks:"
              cat gitleaks-results.json
              exit 1
            else
              echo "‚úÖ No secrets detected by GitLeaks"
            fi
          else
            echo "‚úÖ No secrets detected by GitLeaks"
          fi

      - name: Upload secret scan results
        uses: actions/upload-artifact@v4
        with:
          name: secret-scan-results
          path: |
            gitleaks-results.json
          if-no-files-found: ignore

  # -----------------------------
  # Git Tagging (for releases)
  # -----------------------------
  git-tagging:
    name: üè∑Ô∏è Git Tagging
    runs-on: ubuntu-latest
    needs: [semantic-versioning, flutter-build-test, sast-scan, dependency-scan, docker-build-scan-push, secret-scan, api-keys-detection]
    if: needs.semantic-versioning.outputs.is-release == 'true' && github.event_name == 'push'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Create Git tag
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          TAG_NAME="${{ needs.semantic-versioning.outputs.git-tag }}"
          VERSION="${{ needs.semantic-versioning.outputs.version }}"
          
          echo "üè∑Ô∏è Creating tag: $TAG_NAME"
          
          # Create annotated tag
          git tag -a "$TAG_NAME" -m "Release version $VERSION"
          
          # Push tag
          git push origin "$TAG_NAME"
          
          echo "‚úÖ Tag $TAG_NAME created and pushed successfully"

      - name: Create GitHub Release
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: ${{ needs.semantic-versioning.outputs.git-tag }}
          release_name: Release ${{ needs.semantic-versioning.outputs.version }}
          body: |
            ## üöÄ Release ${{ needs.semantic-versioning.outputs.version }}
            
            ### üìã Version Information
            - **Version**: ${{ needs.semantic-versioning.outputs.version }}
            - **Version Type**: ${{ needs.semantic-versioning.outputs.version-type }}
            - **Commit**: `${{ github.sha }}`
            - **Branch**: `${{ github.ref_name }}`
            
            ### üîß Build Information
            - **Flutter Version**: ${{ env.FLUTTER_VERSION }}
            - **Dart Version**: ${{ env.DART_VERSION }}
            - **Java Version**: ${{ env.JAVA_VERSION }}
            
            ### üì¶ Artifacts
            - **Docker Image**: `${{ secrets.DOCKER_USERNAME }}/flutter-app:v${{ needs.semantic-versioning.outputs.version }}-prod`
            - **Build Artifacts**: `flutter-builds-v${{ needs.semantic-versioning.outputs.version }}-${{ github.sha }}`
            
            ### üîí Security Scans
            - ‚úÖ SAST Scan (Semgrep): ${{ needs.sast-scan.result }}
            - ‚úÖ Dependency Scan (Trivy): ${{ needs.dependency-scan.result }}
            - ‚úÖ Docker Scan (Trivy): ${{ needs.docker-build-scan-push.result }}
            - ‚úÖ Secret Scan: ${{ needs.secret-scan.result }}
            
            ### üìù Commit Message
            ```
            ${{ github.event.head_commit.message }}
            ```
          draft: false
          prerelease: false

  # -----------------------------
  # Security Summary
  # -----------------------------
  security-summary:
    name: üìä Security Summary
    runs-on: ubuntu-latest
    needs: [semantic-versioning, sast-scan, codeql-analysis, dependency-scan, docker-build-scan-push, secret-scan, api-keys-detection, git-tagging]
    if: always()

    steps:
      - name: Security Scan Results
        run: |
          echo "## üîí Security Scan Summary" >> $GITHUB_STEP_SUMMARY
          echo "| Scan Type | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| SAST (Semgrep) | ${{ needs.sast-scan.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| CodeQL Analysis | ${{ needs.codeql-analysis.result || 'Skipped' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Dependency (Trivy FS) | ${{ needs.dependency-scan.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Dependency (Snyk) | ${{ needs.dependency-scan.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Docker (Trivy Image) | ${{ needs.docker-build-scan-push.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Secret Scan | ${{ needs.secret-scan.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| API Keys Detection | ${{ needs.api-keys-detection.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| DAST (ZAP) | ${{ needs.dast-scan.result || 'Skipped' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## üìã Version & Release Information" >> $GITHUB_STEP_SUMMARY
          echo "| Property | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Version** | v${{ needs.semantic-versioning.outputs.version }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Version Type** | ${{ needs.semantic-versioning.outputs.version-type }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Git Tag** | ${{ needs.semantic-versioning.outputs.git-tag }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Is Release** | ${{ needs.semantic-versioning.outputs.is-release }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Git Tagging** | ${{ needs.git-tagging.result || 'Skipped' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## üöÄ Performance Optimizations Applied:" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Semantic Versioning**: Automatic version calculation based on conventional commits" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Git Tagging**: Automatic tag creation for releases" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **GitHub Releases**: Automatic release creation with detailed changelog" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Flutter/Dart dependency caching**" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Artifact reuse for Docker builds**" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Combined Trivy install/scan steps**" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Merged Docker build/scan/push jobs**" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Aggressive Docker layer caching**" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Multi-platform builds (AMD64/ARM64)**" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Parameterized Docker username**" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **DAST scanning enabled for testing (push/PR triggers)**" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Enhanced security scanning with Snyk**" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **OWASP ZAP DAST implementation**" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Secret scanning with TruffleHog & GitLeaks**" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **API keys detection scanner**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## üìù Usage Instructions:" >> $GITHUB_STEP_SUMMARY
          echo "### Conventional Commits for Versioning:" >> $GITHUB_STEP_SUMMARY
          echo "- \`feat:\` ‚Üí Minor version bump (1.0.0 ‚Üí 1.1.0)" >> $GITHUB_STEP_SUMMARY
          echo "- \`fix:\` ‚Üí Patch version bump (1.0.0 ‚Üí 1.0.1)" >> $GITHUB_STEP_SUMMARY
          echo "- \`feat!:\` or \`BREAKING CHANGE:\` ‚Üí Major version bump (1.0.0 ‚Üí 2.0.0)" >> $GITHUB_STEP_SUMMARY
          echo "- Branches \`release/*\` ‚Üí Minor version bump" >> $GITHUB_STEP_SUMMARY
          echo "- Branches \`hotfix/*\` ‚Üí Patch version bump" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Note:** Docker username is now automatically taken from DOCKER_USERNAME secret." >> $GITHUB_STEP_SUMMARY
          echo "**Security:** Add SNYK_TOKEN secret for enhanced dependency scanning." >> $GITHUB_STEP_SUMMARY
